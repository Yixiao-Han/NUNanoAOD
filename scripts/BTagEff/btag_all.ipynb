{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cafde-df82-47a4-85a3-eb4d32b248bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"YOUR_CLIENT\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c1f8a7-87a4-44c2-92d3-980f7b440d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import awkward as ak\n",
    "import uproot\n",
    "import coffea\n",
    "import coffea.processor as processor\n",
    "from coffea import hist\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c564d25-dbd5-4911-955d-125ff2ee6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2016postVFP'\n",
    "\n",
    "\n",
    "with open(\"HLT_Run2_UL.yaml\", 'r') as f_yml:\n",
    "    dict_HLT = yaml.load(f_yml, Loader=yaml.FullLoader)\n",
    "\n",
    "hlt_ls = [_hlt.split('HLT_')[-1] for _hlt_ls in dict_HLT[year[:4]].values() for _hlt in _hlt_ls]\n",
    "\n",
    "with open(f'{year}_MC.txt') as f_tt:\n",
    "    lines = f_tt.read().splitlines()\n",
    "\n",
    "fileset_TT = [''.join(['root://xcache/', line]) for line in lines]\n",
    "\n",
    "fileset_MC_Data = {'TT': fileset_TT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146339a4-3b26-4423-ac10-0ca3a12c0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trig_Processor(processor.ProcessorABC):\n",
    "    def __init__(self, hlts_lep, era=2018):\n",
    "        self.era = era\n",
    "        self.hlts_lep = hlts_lep\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"\")\n",
    "\n",
    "        # 2.4 because of b-jet cuts, 1.5 because of ECAL region\n",
    "        bins_pt = [30, 50, 100, 200, 400, 800]\n",
    "        bins_eta = [-2.4, -1.5, -0.7, 0, 0.7, 1.5, 2.4]\n",
    "\n",
    "        axis_pt = hist.Bin(\"pT\", \"pT [GeV]\", bins_pt)\n",
    "        axis_eta = hist.Bin(\"eta\", \"eta [AU]\", bins_eta)\n",
    "        \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            # bottom\n",
    "            'h_num_b': hist.Hist('h_num_b', dataset_axis, axis_pt, axis_eta),\n",
    "            'h_den_b': hist.Hist('h_den_b', dataset_axis, axis_pt, axis_eta),\n",
    "            # charm\n",
    "            'h_num_c': hist.Hist('h_num_c', dataset_axis, axis_pt, axis_eta),\n",
    "            'h_den_c': hist.Hist('h_den_c', dataset_axis, axis_pt, axis_eta),\n",
    "            # light\n",
    "            'h_num_l': hist.Hist('h_num_l', dataset_axis, axis_pt, axis_eta),\n",
    "            'h_den_l': hist.Hist('h_den_l', dataset_axis, axis_pt, axis_eta),\n",
    "        })\n",
    "\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "    \n",
    "\n",
    "    def flt_HLT(self, events, hlt_avail):\n",
    "        hlt_good = [hlt for hlt in self.hlts_lep if hlt in hlt_avail]\n",
    "        mask_hlt = eval(' | '.join(([f'events.HLT.{hlt}' for hlt in hlt_good])))\n",
    "        events_flt = events[mask_hlt]\n",
    "\n",
    "        return events_flt\n",
    "\n",
    "\n",
    "    def get_good_jets(self, jets):\n",
    "        jets = jets[jets.jetId == 6]\n",
    "        jets = jets[jets.pt >= 30.]\n",
    "        jets = jets[abs(jets.eta) < 4.7]\n",
    "        return jets\n",
    "\n",
    "\n",
    "    def btag_id(self, wp):\n",
    "        # using deepjet\n",
    "        # ref : https://twiki.cern.ch/twiki/bin/view/CMS/BtagRecommendation\n",
    "        dict_wp = {\"2016preVFP\": {\"loose\": 0.0508, \"medium\": 0.2598, \"tight\": 0.6502},\n",
    "                   \"2016postVFP\": {\"loose\": 0.0480, \"medium\": 0.2489, \"tight\": 0.6377},\n",
    "                   \"2017\": {\"loose\": 0.0532, \"medium\": 0.3040, \"tight\": 0.7476},\n",
    "                   \"2018\": {\"loose\": 0.0490, \"medium\": 0.2783, \"tight\": 0.7100},}\n",
    "        return dict_wp[self.era][wp]\n",
    "\n",
    "\n",
    "    def process(self, events):\n",
    "        output = self.accumulator.identity()\n",
    "        dataset = events.metadata[\"dataset\"]\n",
    "        \n",
    "        # HLT\n",
    "        hlt_avail = events.HLT.layout.keys()\n",
    "        events = self.flt_HLT(events, hlt_avail)\n",
    "\n",
    "        # good jets\n",
    "        jets = self.get_good_jets(events.Jet)\n",
    "        b_jets = jets[jets.hadronFlavour==5]\n",
    "        c_jets = jets[jets.hadronFlavour==4]\n",
    "        l_jets = jets[jets.hadronFlavour==0]\n",
    "        \n",
    "        # tagged jets\n",
    "        wp = self.btag_id('loose')\n",
    "        b_btag_jets = b_jets[b_jets.btagDeepFlavB>wp]\n",
    "        c_btag_jets = c_jets[c_jets.btagDeepFlavB>wp]\n",
    "        l_btag_jets = l_jets[l_jets.btagDeepFlavB>wp]\n",
    "\n",
    "        # get pT and eta\n",
    "        b_num_pt = ak.flatten(b_btag_jets.pt, axis=None)\n",
    "        b_num_eta = ak.flatten(b_btag_jets.eta, axis=None)\n",
    "        b_den_pt = ak.flatten(b_jets.pt, axis=None)\n",
    "        b_den_eta = ak.flatten(b_jets.eta, axis=None)\n",
    "\n",
    "        c_num_pt = ak.flatten(c_btag_jets.pt, axis=None)\n",
    "        c_num_eta = ak.flatten(c_btag_jets.eta, axis=None)\n",
    "        c_den_pt = ak.flatten(c_jets.pt, axis=None)\n",
    "        c_den_eta = ak.flatten(c_jets.eta, axis=None)\n",
    "\n",
    "        l_num_pt = ak.flatten(l_btag_jets.pt, axis=None)\n",
    "        l_num_eta = ak.flatten(l_btag_jets.eta, axis=None)\n",
    "        l_den_pt = ak.flatten(l_jets.pt, axis=None)\n",
    "        l_den_eta = ak.flatten(l_jets.eta, axis=None)\n",
    "\n",
    "        # fill histograms\n",
    "        output['h_num_b'].fill(dataset=dataset, pT=b_num_pt, eta=b_num_eta)\n",
    "        output['h_den_b'].fill(dataset=dataset, pT=b_den_pt, eta=b_den_eta)\n",
    "\n",
    "        output['h_num_c'].fill(dataset=dataset, pT=c_num_pt, eta=c_num_eta)\n",
    "        output['h_den_c'].fill(dataset=dataset, pT=c_den_pt, eta=c_den_eta)\n",
    "\n",
    "        output['h_num_l'].fill(dataset=dataset, pT=l_num_pt, eta=l_num_eta)\n",
    "        output['h_den_l'].fill(dataset=dataset, pT=l_den_pt, eta=l_den_eta)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb64c478-dff6-4dd8-b557-bff11b7d99a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  4min  3.5s\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bytesread': 2178673866,\n",
       " 'columns': ['HLT_IsoTkMu24',\n",
       "  'nJet',\n",
       "  'HLT_IsoMu20',\n",
       "  'HLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL_DZ',\n",
       "  'HLT_Ele27_WPTight_Gsf',\n",
       "  'HLT_IsoMu24',\n",
       "  'HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ',\n",
       "  'HLT_IsoTkMu22',\n",
       "  'Jet_jetId',\n",
       "  'HLT_Mu17_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL',\n",
       "  'HLT_Mu17_TrkIsoVVL_TkMu8_TrkIsoVVL_DZ',\n",
       "  'HLT_Ele35_WPLoose_Gsf',\n",
       "  'HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL',\n",
       "  'Jet_pt',\n",
       "  'Jet_hadronFlavour',\n",
       "  'HLT_Ele27_eta2p1_WPLoose_Gsf',\n",
       "  'HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL',\n",
       "  'Jet_btagDeepFlavB',\n",
       "  'HLT_Mu17_TrkIsoVVL_TkMu8_TrkIsoVVL',\n",
       "  'HLT_Ele25_eta2p1_WPTight_Gsf',\n",
       "  'HLT_IsoTkMu20',\n",
       "  'HLT_IsoMu22',\n",
       "  'HLT_Mu8_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL',\n",
       "  'HLT_Mu8_TrkIsoVVL_Ele17_CaloIdL_TrackIdL_IsoVL',\n",
       "  'Jet_eta'],\n",
       " 'entries': 43546000,\n",
       " 'processtime': 3400.131105899811,\n",
       " 'chunks': 49}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = processor.DaskExecutor(client=client)\n",
    "\n",
    "run = processor.Runner(executor=executor,\n",
    "                       schema=processor.NanoAODSchema,\n",
    "                       savemetrics=True,\n",
    "                       chunksize=10000*1000)\n",
    "\n",
    "output, metrics = run(fileset=fileset_MC_Data,\n",
    "                      treename=\"Events\",\n",
    "                      processor_instance=Trig_Processor(era=year, hlts_lep=hlt_ls),)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53859b03-a019-41c3-afb9-ad7f9a228807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'btag_output_{year}.pickle', 'wb') as handle:\n",
    "    pickle.dump(output, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f'btag_output_{year}.pickle', 'rb') as handle:\n",
    "    output = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6126388-ad8e-4660-9bb2-cf8af28b5cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing h_num_b\n",
      "Writing h_den_b\n",
      "Writing h_num_c\n",
      "Writing h_den_c\n",
      "Writing h_num_l\n",
      "Writing h_den_l\n"
     ]
    }
   ],
   "source": [
    "f_out = uproot.recreate(f\"bTagEff_{year}.root\")\n",
    "\n",
    "for h_name, histo in output.items():\n",
    "    print('Writing', h_name)\n",
    "    f_out[h_name] = histo['TT'].sum('dataset').to_hist()\n",
    "\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf326a-0e73-4ea5-987e-87ed1362bed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
