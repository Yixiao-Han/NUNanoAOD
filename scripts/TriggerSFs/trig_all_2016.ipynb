{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b01e2-c18f-4073-8461-0faafb60d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"YOUR_CLIENT\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c1f8a7-87a4-44c2-92d3-980f7b440d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import awkward as ak\n",
    "import uproot\n",
    "import coffea\n",
    "import coffea.processor as processor\n",
    "from coffea import hist\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c564d25-dbd5-4911-955d-125ff2ee6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2016'\n",
    "\n",
    "\n",
    "with open(\"HLT_Run2_UL.yaml\", 'r') as f_yml:\n",
    "    dict_HLT = yaml.load(f_yml, Loader=yaml.FullLoader)\n",
    "\n",
    "hlt_ls = [_hlt.split('HLT_')[-1] for _hlt_ls in dict_HLT[year].values() for _hlt in _hlt_ls]\n",
    "\n",
    "with open(f'{year}_MC_pre.txt') as f_tt:\n",
    "    lines = f_tt.read().splitlines()\n",
    "\n",
    "fileset_TT_pre = [''.join(['root://xcache/', line]) for line in lines]\n",
    "\n",
    "with open(f'{year}_MC_post.txt') as f_tt:\n",
    "    lines = f_tt.read().splitlines()\n",
    "\n",
    "fileset_TT_post = [''.join(['root://xcache/', line]) for line in lines]\n",
    "\n",
    "with open(f'{year}_data.txt') as f_tt:\n",
    "    lines = f_tt.read().splitlines()\n",
    "\n",
    "fileset_MET = [''.join(['root://xcache/', line]) for line in lines]\n",
    "\n",
    "fileset_MC_Data = {'TT_pre': fileset_TT_pre, 'TT_post': fileset_TT_post, 'data_MET': fileset_MET}\n",
    "# fileset_MC_Data = {'TT': fileset_TT[:3], 'data_MET': fileset_MET[:3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146339a4-3b26-4423-ac10-0ca3a12c0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trig_Processor(processor.ProcessorABC):\n",
    "    def __init__(self, isMC, hlts_lep, era=2018):\n",
    "        self.isMC = isMC\n",
    "        self.era = era\n",
    "        self.hlts_lep = hlts_lep\n",
    "        self.hlts_met = ['PFMET100_PFMHT100_IDTight_PFHT60',\n",
    "                         'PFMET110_PFMHT110_IDTight',\n",
    "                         'PFMET120_PFMHT120_IDTight',\n",
    "                         'PFMET120_PFMHT120_IDTight_PFHT60',\n",
    "                         'PFMET130_PFMHT130_IDTight',\n",
    "                         'PFMET140_PFMHT140_IDTight',\n",
    "                         'PFMET200_HBHECleaned',\n",
    "                         'PFMET200_HBHE_BeamHaloCleaned',\n",
    "                         'PFMET200_NotCleaned',\n",
    "                         'PFMET250_HBHECleaned',\n",
    "                         'PFMET300_HBHECleaned',\n",
    "                         'PFMETNoMu100_PFMHTNoMu100_IDTight_PFHT60',\n",
    "                         'PFMETNoMu110_PFMHTNoMu110_IDTight',\n",
    "                         'PFMETNoMu120_PFMHTNoMu120_IDTight',\n",
    "                         'PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60',\n",
    "                         'PFMETNoMu130_PFMHTNoMu130_IDTight',\n",
    "                         'PFMETNoMu140_PFMHTNoMu140_IDTight',\n",
    "                         'PFMETTypeOne100_PFMHT100_IDTight_PFHT60',\n",
    "                         'PFMETTypeOne110_PFMHT110_IDTight',\n",
    "                         'PFMETTypeOne120_PFMHT120_IDTight',\n",
    "                         'PFMETTypeOne120_PFMHT120_IDTight_PFHT60',\n",
    "                         'PFMETTypeOne130_PFMHT130_IDTight',\n",
    "                         'PFMETTypeOne140_PFMHT140_IDTight',\n",
    "                         'PFMETTypeOne200_HBHE_BeamHaloCleaned']\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"\")\n",
    "        bins = [20, 25, 30, 35, 40, 50, 60, 70]\n",
    "        lead_axis = hist.Bin(\"lead\", \"pT lead [GeV]\", bins)\n",
    "        trail_axis = hist.Bin(\"trail\", \"pT trail [GeV]\", bins)\n",
    "        \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'h_num_MM_EE': hist.Hist('num_MM_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_ME_EE': hist.Hist('num_ME_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EM_EE': hist.Hist('num_EM_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EE_EE': hist.Hist('num_EE_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_MM_EE': hist.Hist('den_MM_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_ME_EE': hist.Hist('den_ME_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EM_EE': hist.Hist('den_EM_EE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EE_EE': hist.Hist('den_EE_EE', dataset_axis, lead_axis, trail_axis),\n",
    "\n",
    "            'h_num_MM_EB': hist.Hist('num_MM_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_ME_EB': hist.Hist('num_ME_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EM_EB': hist.Hist('num_EM_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EE_EB': hist.Hist('num_EE_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_MM_EB': hist.Hist('den_MM_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_ME_EB': hist.Hist('den_ME_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EM_EB': hist.Hist('den_EM_EB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EE_EB': hist.Hist('den_EE_EB', dataset_axis, lead_axis, trail_axis),\n",
    "\n",
    "            'h_num_MM_BE': hist.Hist('num_MM_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_ME_BE': hist.Hist('num_ME_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EM_BE': hist.Hist('num_EM_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EE_BE': hist.Hist('num_EE_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_MM_BE': hist.Hist('den_MM_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_ME_BE': hist.Hist('den_ME_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EM_BE': hist.Hist('den_EM_BE', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EE_BE': hist.Hist('den_EE_BE', dataset_axis, lead_axis, trail_axis),\n",
    "\n",
    "            'h_num_MM_BB': hist.Hist('num_MM_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_ME_BB': hist.Hist('num_ME_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EM_BB': hist.Hist('num_EM_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_num_EE_BB': hist.Hist('num_EE_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_MM_BB': hist.Hist('den_MM_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_ME_BB': hist.Hist('den_ME_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EM_BB': hist.Hist('den_EM_BB', dataset_axis, lead_axis, trail_axis),\n",
    "            'h_den_EE_BB': hist.Hist('den_EE_BB', dataset_axis, lead_axis, trail_axis),\n",
    "        })\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    \n",
    "    def process(self, events):\n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        dataset = events.metadata[\"dataset\"]\n",
    "        \n",
    "        # HLT\n",
    "        hlt_avail = events.HLT.layout.keys()\n",
    "        events_MET = self.HLT_MET(events, hlt_avail)\n",
    "        events_LEP = self.HLT_LEP(events_MET, hlt_avail)\n",
    "        \n",
    "        # pt arrays\n",
    "        dic_pt_MET = self.get_pTs_from_events(events_MET)\n",
    "        dic_pt_LEP = self.get_pTs_from_events(events_LEP)\n",
    "\n",
    "        output['h_num_MM_EE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_MM_EE'], trail=dic_pt_LEP['pt_trail_MM_EE'])\n",
    "        output['h_num_ME_EE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_ME_EE'], trail=dic_pt_LEP['pt_trail_ME_EE'])\n",
    "        output['h_num_EM_EE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EM_EE'], trail=dic_pt_LEP['pt_trail_EM_EE'])\n",
    "        output['h_num_EE_EE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EE_EE'], trail=dic_pt_LEP['pt_trail_EE_EE'])\n",
    "\n",
    "        output['h_den_MM_EE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_MM_EE'], trail=dic_pt_MET['pt_trail_MM_EE'])\n",
    "        output['h_den_ME_EE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_ME_EE'], trail=dic_pt_MET['pt_trail_ME_EE'])\n",
    "        output['h_den_EM_EE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EM_EE'], trail=dic_pt_MET['pt_trail_EM_EE'])\n",
    "        output['h_den_EE_EE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EE_EE'], trail=dic_pt_MET['pt_trail_EE_EE'])\n",
    "\n",
    "        output['h_num_MM_EB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_MM_EB'], trail=dic_pt_LEP['pt_trail_MM_EB'])\n",
    "        output['h_num_ME_EB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_ME_EB'], trail=dic_pt_LEP['pt_trail_ME_EB'])\n",
    "        output['h_num_EM_EB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EM_EB'], trail=dic_pt_LEP['pt_trail_EM_EB'])\n",
    "        output['h_num_EE_EB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EE_EB'], trail=dic_pt_LEP['pt_trail_EE_EB'])\n",
    "\n",
    "        output['h_den_MM_EB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_MM_EB'], trail=dic_pt_MET['pt_trail_MM_EB'])\n",
    "        output['h_den_ME_EB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_ME_EB'], trail=dic_pt_MET['pt_trail_ME_EB'])\n",
    "        output['h_den_EM_EB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EM_EB'], trail=dic_pt_MET['pt_trail_EM_EB'])\n",
    "        output['h_den_EE_EB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EE_EB'], trail=dic_pt_MET['pt_trail_EE_EB'])\n",
    "\n",
    "        output['h_num_MM_BE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_MM_BE'], trail=dic_pt_LEP['pt_trail_MM_BE'])\n",
    "        output['h_num_ME_BE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_ME_BE'], trail=dic_pt_LEP['pt_trail_ME_BE'])\n",
    "        output['h_num_EM_BE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EM_BE'], trail=dic_pt_LEP['pt_trail_EM_BE'])\n",
    "        output['h_num_EE_BE'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EE_BE'], trail=dic_pt_LEP['pt_trail_EE_BE'])\n",
    "\n",
    "        output['h_den_MM_BE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_MM_BE'], trail=dic_pt_MET['pt_trail_MM_BE'])\n",
    "        output['h_den_ME_BE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_ME_BE'], trail=dic_pt_MET['pt_trail_ME_BE'])\n",
    "        output['h_den_EM_BE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EM_BE'], trail=dic_pt_MET['pt_trail_EM_BE'])\n",
    "        output['h_den_EE_BE'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EE_BE'], trail=dic_pt_MET['pt_trail_EE_BE'])\n",
    "\n",
    "        output['h_num_MM_BB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_MM_BB'], trail=dic_pt_LEP['pt_trail_MM_BB'])\n",
    "        output['h_num_ME_BB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_ME_BB'], trail=dic_pt_LEP['pt_trail_ME_BB'])\n",
    "        output['h_num_EM_BB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EM_BB'], trail=dic_pt_LEP['pt_trail_EM_BB'])\n",
    "        output['h_num_EE_BB'].fill(dataset=dataset, lead=dic_pt_LEP['pt_lead_EE_BB'], trail=dic_pt_LEP['pt_trail_EE_BB'])\n",
    "\n",
    "        output['h_den_MM_BB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_MM_BB'], trail=dic_pt_MET['pt_trail_MM_BB'])\n",
    "        output['h_den_ME_BB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_ME_BB'], trail=dic_pt_MET['pt_trail_ME_BB'])\n",
    "        output['h_den_EM_BB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EM_BB'], trail=dic_pt_MET['pt_trail_EM_BB'])\n",
    "        output['h_den_EE_BB'].fill(dataset=dataset, lead=dic_pt_MET['pt_lead_EE_BB'], trail=dic_pt_MET['pt_trail_EE_BB'])\n",
    "\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "    \n",
    "\n",
    "    def HLT_MET(self, events, hlt_avail):\n",
    "        hlt_good = [hlt for hlt in self.hlts_met if hlt in hlt_avail]\n",
    "        mask_hlt = eval(' | '.join(([f'events.HLT.{hlt}' for hlt in hlt_good])))\n",
    "        events_MET = events[mask_hlt]\n",
    "\n",
    "        return events_MET\n",
    "\n",
    "\n",
    "    def HLT_LEP(self, events, hlt_avail):\n",
    "        hlt_good = [hlt for hlt in self.hlts_lep if hlt in hlt_avail]\n",
    "        mask_hlt = eval(' | '.join(([f'events.HLT.{hlt}' for hlt in hlt_good])))\n",
    "        events_LEP = events[mask_hlt]\n",
    "\n",
    "        return events_LEP\n",
    "\n",
    "\n",
    "    def get_good_muons(self, muons):\n",
    "        muons = muons[abs(muons.eta) < 2.4]\n",
    "        # muons.pt >= (25 if idx==0 else 20)\n",
    "        muons = muons[muons.pt >= 20]\n",
    "        muons = muons[muons.tightId] \n",
    "        muons = muons[muons.pfRelIso04_all <= 0.15]\n",
    "        muons = muons[abs(muons.dxy) < 0.02]  \n",
    "        muons = muons[abs(muons.dz) < 0.1]\n",
    "        return muons\n",
    "\n",
    "    def get_good_electrons(self, electrons):\n",
    "        electrons = electrons[abs(electrons.eta) < 2.5]\n",
    "        # skip 25 GeV\n",
    "        electrons = electrons[electrons.pt >= 20]\n",
    "        electrons = electrons[electrons.mvaFall17V2Iso_WP90] \n",
    "        return electrons\n",
    "\n",
    "    def get_pTs_from_events(self, events):\n",
    "        # dictionary to be returned\n",
    "        dic_pt = {}\n",
    "\n",
    "        # get leptons\n",
    "        good_Ms = self.get_good_muons(events.Muon)\n",
    "        good_Es = self.get_good_electrons(events.Electron)\n",
    "\n",
    "        # at least 2 leptons\n",
    "        mask_ll = ak.num(good_Ms) + ak.num(good_Es) >= 2\n",
    "        good_Ls = ak.concatenate([good_Ms[mask_ll], good_Es[mask_ll]], axis=1)\n",
    "        id_sort = ak.argsort(good_Ls.pt, ascending=False)\n",
    "        good_Ls = good_Ls[id_sort]\n",
    "        good_Ls = good_Ls[:,:2]\n",
    "\n",
    "        # pdgID\n",
    "        id_prod = abs(good_Ls.pdgId[:,0] * good_Ls.pdgId[:,1])\n",
    "\n",
    "        # ElEl\n",
    "        mask_ElEl = id_prod==121\n",
    "        good_ElEl = good_Ls[mask_ElEl]\n",
    "\n",
    "        mask_0Br = good_ElEl.eta[:,0] < 1.5\n",
    "        mask_1Br = good_ElEl.eta[:,1] < 1.5\n",
    "        mask_0Ec = good_ElEl.eta[:,0] > 1.5\n",
    "        mask_1Ec = good_ElEl.eta[:,1] > 1.5\n",
    "\n",
    "        mask_BrBr = mask_0Br & mask_1Br\n",
    "        mask_BrEc = mask_0Br & mask_1Ec\n",
    "        mask_EcBr = mask_0Ec & mask_1Br\n",
    "        mask_EcEc = mask_0Ec & mask_1Ec\n",
    "\n",
    "        dic_pt['pt_lead_EE_BB'] = good_ElEl[mask_BrBr].pt[:,0]\n",
    "        dic_pt['pt_trail_EE_BB'] = good_ElEl[mask_BrBr].pt[:,1]\n",
    "        dic_pt['pt_lead_EE_BE'] = good_ElEl[mask_BrEc].pt[:,0]\n",
    "        dic_pt['pt_trail_EE_BE'] = good_ElEl[mask_BrEc].pt[:,1]\n",
    "        dic_pt['pt_lead_EE_EB'] = good_ElEl[mask_EcBr].pt[:,0]\n",
    "        dic_pt['pt_trail_EE_EB'] = good_ElEl[mask_EcBr].pt[:,1]\n",
    "        dic_pt['pt_lead_EE_EE'] = good_ElEl[mask_EcEc].pt[:,0]\n",
    "        dic_pt['pt_trail_EE_EE'] = good_ElEl[mask_EcEc].pt[:,1]\n",
    "\n",
    "        # MuMu\n",
    "        mask_MuMu = id_prod==169\n",
    "        good_MuMu = good_Ls[mask_MuMu]\n",
    "\n",
    "        mask_0Br = good_MuMu.eta[:,0] < 1.5\n",
    "        mask_1Br = good_MuMu.eta[:,1] < 1.5\n",
    "        mask_0Ec = good_MuMu.eta[:,0] > 1.5\n",
    "        mask_1Ec = good_MuMu.eta[:,1] > 1.5\n",
    "\n",
    "        mask_BrBr = mask_0Br & mask_1Br\n",
    "        mask_BrEc = mask_0Br & mask_1Ec\n",
    "        mask_EcBr = mask_0Ec & mask_1Br\n",
    "        mask_EcEc = mask_0Ec & mask_1Ec\n",
    "\n",
    "        dic_pt['pt_lead_MM_BB'] = good_MuMu[mask_BrBr].pt[:,0]\n",
    "        dic_pt['pt_trail_MM_BB'] = good_MuMu[mask_BrBr].pt[:,1]\n",
    "        dic_pt['pt_lead_MM_BE'] = good_MuMu[mask_BrEc].pt[:,0]\n",
    "        dic_pt['pt_trail_MM_BE'] = good_MuMu[mask_BrEc].pt[:,1]\n",
    "        dic_pt['pt_lead_MM_EB'] = good_MuMu[mask_EcBr].pt[:,0]\n",
    "        dic_pt['pt_trail_MM_EB'] = good_MuMu[mask_EcBr].pt[:,1]\n",
    "        dic_pt['pt_lead_MM_EE'] = good_MuMu[mask_EcEc].pt[:,0]\n",
    "        dic_pt['pt_trail_MM_EE'] = good_MuMu[mask_EcEc].pt[:,1]\n",
    "\n",
    "        # Mix\n",
    "        mask_mix = id_prod==143\n",
    "        good_mix = good_Ls[mask_mix]\n",
    "\n",
    "        # ElMu\n",
    "        mask_ElMu = abs(good_mix.pdgId[:,0])==11\n",
    "        good_ElMu = good_mix[mask_ElMu]\n",
    "\n",
    "        mask_0Br = good_ElMu.eta[:,0] < 1.5\n",
    "        mask_1Br = good_ElMu.eta[:,1] < 1.5\n",
    "        mask_0Ec = good_ElMu.eta[:,0] > 1.5\n",
    "        mask_1Ec = good_ElMu.eta[:,1] > 1.5\n",
    "\n",
    "        mask_BrBr = mask_0Br & mask_1Br\n",
    "        mask_BrEc = mask_0Br & mask_1Ec\n",
    "        mask_EcBr = mask_0Ec & mask_1Br\n",
    "        mask_EcEc = mask_0Ec & mask_1Ec\n",
    "\n",
    "        dic_pt['pt_lead_EM_BB'] = good_ElMu[mask_BrBr].pt[:,0]\n",
    "        dic_pt['pt_trail_EM_BB'] = good_ElMu[mask_BrBr].pt[:,1]\n",
    "        dic_pt['pt_lead_EM_BE'] = good_ElMu[mask_BrEc].pt[:,0]\n",
    "        dic_pt['pt_trail_EM_BE'] = good_ElMu[mask_BrEc].pt[:,1]\n",
    "        dic_pt['pt_lead_EM_EB'] = good_ElMu[mask_EcBr].pt[:,0]\n",
    "        dic_pt['pt_trail_EM_EB'] = good_ElMu[mask_EcBr].pt[:,1]\n",
    "        dic_pt['pt_lead_EM_EE'] = good_ElMu[mask_EcEc].pt[:,0]\n",
    "        dic_pt['pt_trail_EM_EE'] = good_ElMu[mask_EcEc].pt[:,1]\n",
    "\n",
    "        # MuEl\n",
    "        mask_MuEl = abs(good_mix.pdgId[:,0])==13\n",
    "        good_MuEl = good_mix[mask_MuEl]\n",
    "\n",
    "        mask_0Br = good_MuEl.eta[:,0] < 1.5\n",
    "        mask_1Br = good_MuEl.eta[:,1] < 1.5\n",
    "        mask_0Ec = good_MuEl.eta[:,0] > 1.5\n",
    "        mask_1Ec = good_MuEl.eta[:,1] > 1.5\n",
    "\n",
    "        mask_BrBr = mask_0Br & mask_1Br\n",
    "        mask_BrEc = mask_0Br & mask_1Ec\n",
    "        mask_EcBr = mask_0Ec & mask_1Br\n",
    "        mask_EcEc = mask_0Ec & mask_1Ec\n",
    "\n",
    "        dic_pt['pt_lead_ME_BB'] = good_MuEl[mask_BrBr].pt[:,0]\n",
    "        dic_pt['pt_trail_ME_BB'] = good_MuEl[mask_BrBr].pt[:,1]\n",
    "        dic_pt['pt_lead_ME_BE'] = good_MuEl[mask_BrEc].pt[:,0]\n",
    "        dic_pt['pt_trail_ME_BE'] = good_MuEl[mask_BrEc].pt[:,1]\n",
    "        dic_pt['pt_lead_ME_EB'] = good_MuEl[mask_EcBr].pt[:,0]\n",
    "        dic_pt['pt_trail_ME_EB'] = good_MuEl[mask_EcBr].pt[:,1]\n",
    "        dic_pt['pt_lead_ME_EE'] = good_MuEl[mask_EcEc].pt[:,0]\n",
    "        dic_pt['pt_trail_ME_EE'] = good_MuEl[mask_EcEc].pt[:,1]\n",
    "\n",
    "        return dic_pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb64c478-dff6-4dd8-b557-bff11b7d99a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 14min 38.9s\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bytesread': 6856075503,\n",
       " 'columns': ['HLT_IsoMu20',\n",
       "  'HLT_PFMET120_PFMHT120_IDTight',\n",
       "  'Electron_pt',\n",
       "  'HLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL_DZ',\n",
       "  'HLT_Mu17_TrkIsoVVL_TkMu8_TrkIsoVVL',\n",
       "  'Muon_pt',\n",
       "  'Electron_eta',\n",
       "  'HLT_Mu8_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL',\n",
       "  'HLT_Ele25_eta2p1_WPTight_Gsf',\n",
       "  'HLT_Mu17_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL',\n",
       "  'Muon_pdgId',\n",
       "  'HLT_PFMET110_PFMHT110_IDTight',\n",
       "  'HLT_Ele27_eta2p1_WPLoose_Gsf',\n",
       "  'HLT_Mu8_TrkIsoVVL_Ele17_CaloIdL_TrackIdL_IsoVL',\n",
       "  'HLT_Ele27_WPTight_Gsf',\n",
       "  'HLT_Ele35_WPLoose_Gsf',\n",
       "  'HLT_IsoTkMu20',\n",
       "  'HLT_Mu17_TrkIsoVVL_TkMu8_TrkIsoVVL_DZ',\n",
       "  'HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL',\n",
       "  'HLT_IsoMu24',\n",
       "  'HLT_IsoTkMu24',\n",
       "  'Muon_tightId',\n",
       "  'nMuon',\n",
       "  'Electron_mvaFall17V2Iso_WP90',\n",
       "  'Electron_pdgId',\n",
       "  'HLT_PFMETNoMu110_PFMHTNoMu110_IDTight',\n",
       "  'HLT_IsoMu22',\n",
       "  'HLT_PFMETNoMu120_PFMHTNoMu120_IDTight',\n",
       "  'HLT_IsoTkMu22',\n",
       "  'nElectron',\n",
       "  'HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ',\n",
       "  'Muon_eta',\n",
       "  'Muon_dz',\n",
       "  'Muon_pfRelIso04_all',\n",
       "  'Muon_dxy',\n",
       "  'HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL'],\n",
       " 'entries': 257783210,\n",
       " 'processtime': 34033.37143397331,\n",
       " 'chunks': 250}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = processor.DaskExecutor(client=client)\n",
    "\n",
    "run = processor.Runner(executor=executor,\n",
    "                       schema=processor.NanoAODSchema,\n",
    "                       savemetrics=True,\n",
    "                       chunksize=10000*1000)\n",
    "\n",
    "output, metrics = run(fileset=fileset_MC_Data,\n",
    "                      treename=\"Events\",\n",
    "                      processor_instance=Trig_Processor(isMC=True, hlts_lep=hlt_ls),)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6538f43-59d8-45c0-a289-ae4831f8f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = uproot.recreate(f\"TrigEff_{year}.root\")\n",
    "\n",
    "for h_name, histo in output.items():\n",
    "    # print(h_name, type(histo['data_MET']))\n",
    "    f_out[h_name+'_TT_pre'] = histo['TT_pre'].sum('dataset').to_hist()\n",
    "    f_out[h_name+'_TT_post'] = histo['TT_post'].sum('dataset').to_hist()\n",
    "    f_out[h_name+'_data_MET'] = histo['data_MET'].sum('dataset').to_hist()\n",
    "    \n",
    "f_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b29a2c-3665-46ed-be22-5421d4fdc0eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3270386722.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    @\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae74f0-375f-4a13-8b89-17a261078430",
   "metadata": {},
   "source": [
    "## Check statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52bdf5-fd0d-41f4-983b-0d7eb26f0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1, v1 in output.items():\n",
    "    print(k1, ' ', end='')\n",
    "    for k2, v2 in v1.values().items():\n",
    "        print(k2, 'has # events:', end='')\n",
    "        print(v2.sum(), ' ', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41044744-bc8c-4ca7-af62-6a570af36e69",
   "metadata": {},
   "source": [
    "## Calculate efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d607d5c-ed40-47ef-b47e-87a860d863ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eff = defaultdict(dict)\n",
    "\n",
    "lum_pre = 0.5\n",
    "lum_post = 0.5\n",
    "\n",
    "dict_eff['h_eff_MM_BB']['TT'] = (output['h_num_MM_BB']['TT_pre'].scale(lum_pre)+output['h_num_MM_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_MM_BB']['TT_pre'].scale(lum_pre)+output['h_den_MM_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_BB']['TT'] = (output['h_num_EE_BB']['TT_pre'].scale(lum_pre)+output['h_num_EE_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EE_BB']['TT_pre'].scale(lum_pre)+output['h_den_EE_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_BB']['TT'] = (output['h_num_EM_BB']['TT_pre'].scale(lum_pre)+output['h_num_EM_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EM_BB']['TT_pre'].scale(lum_pre)+output['h_den_EM_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_BB']['TT'] = (output['h_num_ME_BB']['TT_pre'].scale(lum_pre)+output['h_num_ME_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_ME_BB']['TT_pre'].scale(lum_pre)+output['h_den_ME_BB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_BE']['TT'] = (output['h_num_MM_BE']['TT_pre'].scale(lum_pre)+output['h_num_MM_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_MM_BE']['TT_pre'].scale(lum_pre)+output['h_den_MM_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_BE']['TT'] = (output['h_num_EE_BE']['TT_pre'].scale(lum_pre)+output['h_num_EE_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EE_BE']['TT_pre'].scale(lum_pre)+output['h_den_EE_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_BE']['TT'] = (output['h_num_EM_BE']['TT_pre'].scale(lum_pre)+output['h_num_EM_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EM_BE']['TT_pre'].scale(lum_pre)+output['h_den_EM_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_BE']['TT'] = (output['h_num_ME_BE']['TT_pre'].scale(lum_pre)+output['h_num_ME_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_ME_BE']['TT_pre'].scale(lum_pre)+output['h_den_ME_BE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_EB']['TT'] = (output['h_num_MM_EB']['TT_pre'].scale(lum_pre)+output['h_num_MM_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_MM_EB']['TT_pre'].scale(lum_pre)+output['h_den_MM_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_EB']['TT'] = (output['h_num_EE_EB']['TT_pre'].scale(lum_pre)+output['h_num_EE_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EE_EB']['TT_pre'].scale(lum_pre)+output['h_den_EE_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_EB']['TT'] = (output['h_num_EM_EB']['TT_pre'].scale(lum_pre)+output['h_num_EM_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EM_EB']['TT_pre'].scale(lum_pre)+output['h_den_EM_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_EB']['TT'] = (output['h_num_ME_EB']['TT_pre'].scale(lum_pre)+output['h_num_ME_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_ME_EB']['TT_pre'].scale(lum_pre)+output['h_den_ME_EB']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_EE']['TT'] = (output['h_num_MM_EE']['TT_pre'].scale(lum_pre)+output['h_num_MM_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_MM_EE']['TT_pre'].scale(lum_pre)+output['h_den_MM_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_EE']['TT'] = (output['h_num_EE_EE']['TT_pre'].scale(lum_pre)+output['h_num_EE_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EE_EE']['TT_pre'].scale(lum_pre)+output['h_den_EE_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_EE']['TT'] = (output['h_num_EM_EE']['TT_pre'].scale(lum_pre)+output['h_num_EM_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_EM_EE']['TT_pre'].scale(lum_pre)+output['h_den_EM_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_EE']['TT'] = (output['h_num_ME_EE']['TT_pre'].scale(lum_pre)+output['h_num_ME_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist() / (output['h_den_ME_EE']['TT_pre'].scale(lum_pre)+output['h_den_ME_EE']['TT_post'].scale(lum_post)).sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_BB']['data_MET'] = output['h_num_MM_BB']['data_MET'].sum('dataset').to_hist() / output['h_den_MM_BB']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_BB']['data_MET'] = output['h_num_EE_BB']['data_MET'].sum('dataset').to_hist() / output['h_den_EE_BB']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_BB']['data_MET'] = output['h_num_EM_BB']['data_MET'].sum('dataset').to_hist() / output['h_den_EM_BB']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_BB']['data_MET'] = output['h_num_ME_BB']['data_MET'].sum('dataset').to_hist() / output['h_den_ME_BB']['data_MET'].sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_BE']['data_MET'] = output['h_num_MM_BE']['data_MET'].sum('dataset').to_hist() / output['h_den_MM_BE']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_BE']['data_MET'] = output['h_num_EE_BE']['data_MET'].sum('dataset').to_hist() / output['h_den_EE_BE']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_BE']['data_MET'] = output['h_num_EM_BE']['data_MET'].sum('dataset').to_hist() / output['h_den_EM_BE']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_BE']['data_MET'] = output['h_num_ME_BE']['data_MET'].sum('dataset').to_hist() / output['h_den_ME_BE']['data_MET'].sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_EB']['data_MET'] = output['h_num_MM_EB']['data_MET'].sum('dataset').to_hist() / output['h_den_MM_EB']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_EB']['data_MET'] = output['h_num_EE_EB']['data_MET'].sum('dataset').to_hist() / output['h_den_EE_EB']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_EB']['data_MET'] = output['h_num_EM_EB']['data_MET'].sum('dataset').to_hist() / output['h_den_EM_EB']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_EB']['data_MET'] = output['h_num_ME_EB']['data_MET'].sum('dataset').to_hist() / output['h_den_ME_EB']['data_MET'].sum('dataset').to_hist()\n",
    "\n",
    "dict_eff['h_eff_MM_EE']['data_MET'] = output['h_num_MM_EE']['data_MET'].sum('dataset').to_hist() / output['h_den_MM_EE']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EE_EE']['data_MET'] = output['h_num_EE_EE']['data_MET'].sum('dataset').to_hist() / output['h_den_EE_EE']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_EM_EE']['data_MET'] = output['h_num_EM_EE']['data_MET'].sum('dataset').to_hist() / output['h_den_EM_EE']['data_MET'].sum('dataset').to_hist()\n",
    "dict_eff['h_eff_ME_EE']['data_MET'] = output['h_num_ME_EE']['data_MET'].sum('dataset').to_hist() / output['h_den_ME_EE']['data_MET'].sum('dataset').to_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec0ca5-fbff-45f5-9072-a997208453a2",
   "metadata": {},
   "source": [
    "## Save efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11f4d3-9780-434f-9c2d-626c53fcae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dict_eff.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_eff, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('dict_eff.pickle', 'rb') as handle:\n",
    "    dict_eff = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e51875-1835-486a-bea6-bc7f62b40953",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defeb107-a50f-4000-81a4-f02ebde4bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dict_eff.items():\n",
    "    plt.figure(figsize=(15,5))\n",
    "    # MC\n",
    "    proc_MC = 'TT'\n",
    "    plt.subplot(1, 3, 1)\n",
    "    v[proc_MC].plot2d()\n",
    "    plt.title(k+' '+proc_MC)\n",
    "    # data\n",
    "    plt.subplot(1, 3, 2)\n",
    "    proc_Data = 'data_MET'\n",
    "    v[proc_Data].plot2d()\n",
    "    plt.title(k+' '+proc_Data)\n",
    "    # SF\n",
    "    plt.subplot(1, 3, 3)\n",
    "    h_SF = v[proc_Data] / v[proc_MC]\n",
    "    h_SF.plot2d()\n",
    "    plt.title(k+' SF')\n",
    "    # space between 2 plots\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733585f-bda3-48e3-b447-c714f76440ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
